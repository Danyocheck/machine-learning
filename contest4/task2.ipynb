{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P2. Лучшая комбинация\n",
    "\n",
    "Ваша задача - обучить стандартный регрессор на основе решающего дерева решать задачу предсказания стоимости бриллианта по набору его признаков, к которым относятся: * Число карат * Цвет * Чистота * Геометрические размеры и т.п.\n",
    "\n",
    "Датасет можно загрузить по [ссылке](https://drive.google.com/drive/u/0/folders/1CAjs-yQQfHFrAAsX9dy_hXGIyc7wx0CH).\n",
    "\n",
    "Датасет необходимо предобработать следующим образом:\n",
    "\n",
    "$\\bullet$\n",
    "Удалить ненужную колонку, дублирующую индекс;\n",
    "\n",
    "$\\bullet$\n",
    "Преобразовать все данные к числовому типу (если это необходимо)*;\n",
    "\n",
    "$\\bullet$\n",
    "Воспользуйтесь One-hot encoder для преобразования категориальных признаков. Категориальными признаками в нашем случае служат признаки \"cut\", \"color\" и \"clarity\";\n",
    "\n",
    "Перемешайте выборку при помощи функции sklearn.utils.shuffle с random_state=42.\n",
    "\n",
    "$\\bullet$\n",
    "Выберите лучшую комбинацию гиперпараметров из предложенных:\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: squared_error, глубина дерева: 12\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: friedman_mse, глубина дерева: 16\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: poisson, глубина дерева: 22\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: squared_error, глубина дерева: 45\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: friedman_mse, глубина дерева: 95\n",
    "\n",
    "$\\bullet$\n",
    "Критерий ветвления: poisson, глубина дерева: 33\n",
    "\n",
    "\n",
    "Лучшим будет тот критерий, который покажет наилучшее среднее качество с точки зрения метрики $r^2$ при кросс-валидации с cv=10. Random state и random seed установите равными 42.\n",
    "\n",
    "## Примечания\n",
    "\n",
    "*Общий алгоритм для этого следующий: вы можете выделить множество всех уникальных значений для каждой колонки, а затем воспользоваться функцией .replace() объекта pandas.DataFrame для замены строчных значений на числовые.\n",
    "\n",
    "Более правильный способ сделать это - воспользоваться классом 'sklearn.preprocessing.LabelEncoder', подробности в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Мы рекомендуем воспользоваться именно LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'criterion': 'squared_error', 'max_depth': 12}\n",
      "Метрика на тестовой выборке: 0.9727742829430988\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Загрузим данные\n",
    "diamonds = pd.read_csv('TRAIN.csv')\n",
    "\n",
    "# Удалим ненужную колонку\n",
    "diamonds.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Преобразуем категориальные признаки\n",
    "cat_features = ['cut', 'color', 'clarity']\n",
    "for feature in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    diamonds[feature] = le.fit_transform(diamonds[feature])\n",
    "    diamonds = pd.concat([diamonds, pd.get_dummies(diamonds[feature], prefix=feature)], axis=1)\n",
    "    diamonds.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "# Перемешаем выборку\n",
    "diamonds = shuffle(diamonds, random_state=42)\n",
    "\n",
    "# Разделим данные на признаки и целевую переменную\n",
    "X = diamonds.drop('price', axis=1)\n",
    "y = diamonds['price']\n",
    "\n",
    "# Разделим данные на тренировочную и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Зададим список параметров для перебора\n",
    "param_grid = [{'criterion': ['friedman_mse'], 'max_depth': [16]}, {'criterion':['squared_error'], 'max_depth': [12]}, {'criterion':['poisson'], 'max_depth': [22]}, {'criterion':['squared_error'], 'max_depth': [45]}, {'criterion':['friedman_mse'], 'max_depth': [95]}, {'criterion':['poisson'], 'max_depth': [33]}]\n",
    "\n",
    "# Создадим экземпляр модели\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Создадим экземпляр GridSearchCV\n",
    "grid_search = GridSearchCV(dt, param_grid, cv=10, scoring='r2')\n",
    "\n",
    "# Обучим модель\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Выведем лучшие параметры и метрику на тестовой выборке\n",
    "print(f'Лучшие параметры: {grid_search.best_params_}')\n",
    "print(f'Метрика на тестовой выборке: {grid_search.score(X_test, y_test)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
